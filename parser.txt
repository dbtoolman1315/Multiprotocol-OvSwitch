#if (FLOW_WC_SEQ != 42)
#define MINIFLOW_ASSERT(X) ovs_assert(X)
BUILD_MESSAGE("FLOW_WC_SEQ changed: miniflow_extract() will have runtime "
               "assertions enabled. Consider updating FLOW_WC_SEQ after "
               "testing")
#else
#define MINIFLOW_ASSERT(X)
#endif

/* True if 'IDX' and higher bits are not set. */
#define ASSERT_FLOWMAP_NOT_SET(FM, IDX)                                 \
{                                                                       \
    MINIFLOW_ASSERT(!((FM)->bits[(IDX) / MAP_T_BITS] &                  \
                      (MAP_MAX << ((IDX) % MAP_T_BITS))));              \
    for (size_t i = (IDX) / MAP_T_BITS + 1; i < FLOWMAP_UNITS; i++) {   \
        MINIFLOW_ASSERT(!(FM)->bits[i]);                                \
    }                                                                   \
}

#define miniflow_set_map(MF, OFS)            \
    {                                        \
    ASSERT_FLOWMAP_NOT_SET(&MF.map, (OFS));  \
    flowmap_set(&MF.map, (OFS), 1);          \
}

#define miniflow_assert_in_map(MF, OFS)              \
    MINIFLOW_ASSERT(flowmap_is_set(&MF.map, (OFS))); \
    ASSERT_FLOWMAP_NOT_SET(&MF.map, (OFS) + 1)

#define miniflow_push_uint64_(MF, OFS, VALUE)              \
{                                                          \
    MINIFLOW_ASSERT(MF.data < MF.end && (OFS) % 8 == 0);   \
    *MF.data++ = VALUE;                                    \
    miniflow_set_map(MF, OFS / 8);                         \
}

#define miniflow_push_be64_(MF, OFS, VALUE)                     \
    miniflow_push_uint64_(MF, OFS, (OVS_FORCE uint64_t)(VALUE))

#define miniflow_push_uint32_(MF, OFS, VALUE)   \
    {                                           \
    MINIFLOW_ASSERT(MF.data < MF.end);          \
                                                \
    if ((OFS) % 8 == 0) {                       \
        miniflow_set_map(MF, OFS / 8);          \
        *(uint32_t *)MF.data = VALUE;           \
    } else if ((OFS) % 8 == 4) {                \
        miniflow_assert_in_map(MF, OFS / 8);    \
        *((uint32_t *)MF.data + 1) = VALUE;     \
        MF.data++;                              \
    }                                           \
}

#define miniflow_push_be32_(MF, OFS, VALUE)                     \
    miniflow_push_uint32_(MF, OFS, (OVS_FORCE uint32_t)(VALUE))

#define miniflow_push_uint16_(MF, OFS, VALUE)   \
{                                               \
    MINIFLOW_ASSERT(MF.data < MF.end);          \
                                                \
    if ((OFS) % 8 == 0) {                       \
        miniflow_set_map(MF, OFS / 8);          \
        *(uint16_t *)MF.data = VALUE;           \
    } else if ((OFS) % 8 == 2) {                \
        miniflow_assert_in_map(MF, OFS / 8);    \
        *((uint16_t *)MF.data + 1) = VALUE;     \
    } else if ((OFS) % 8 == 4) {                \
        miniflow_assert_in_map(MF, OFS / 8);    \
        *((uint16_t *)MF.data + 2) = VALUE;     \
    } else if ((OFS) % 8 == 6) {                \
        miniflow_assert_in_map(MF, OFS / 8);    \
        *((uint16_t *)MF.data + 3) = VALUE;     \
        MF.data++;                              \
    }                                           \
}

#define miniflow_push_uint8_(MF, OFS, VALUE)            \
{                                                       \
    MINIFLOW_ASSERT(MF.data < MF.end);                  \
                                                        \
    if ((OFS) % 8 == 0) {                               \
        miniflow_set_map(MF, OFS / 8);                  \
        *(uint8_t *)MF.data = VALUE;                    \
    } else if ((OFS) % 8 == 7) {                        \
        miniflow_assert_in_map(MF, OFS / 8);            \
        *((uint8_t *)MF.data + 7) = VALUE;              \
        MF.data++;                                      \
    } else {                                            \
        miniflow_assert_in_map(MF, OFS / 8);            \
        *((uint8_t *)MF.data + ((OFS) % 8)) = VALUE;    \
    }                                                   \
}

#define miniflow_pad_to_64_(MF, OFS)                            \
{                                                               \
    MINIFLOW_ASSERT((OFS) % 8 != 0);                            \
    miniflow_assert_in_map(MF, OFS / 8);                        \
                                                                \
    memset((uint8_t *)MF.data + (OFS) % 8, 0, 8 - (OFS) % 8);   \
    MF.data++;                                                  \
}

#define miniflow_pad_from_64_(MF, OFS)                          \
{                                                               \
    MINIFLOW_ASSERT(MF.data < MF.end);                          \
                                                                \
    MINIFLOW_ASSERT((OFS) % 8 != 0);                            \
    miniflow_set_map(MF, OFS / 8);                              \
                                                                \
    memset((uint8_t *)MF.data, 0, (OFS) % 8);                   \
}

#define miniflow_push_be16_(MF, OFS, VALUE)                     \
    miniflow_push_uint16_(MF, OFS, (OVS_FORCE uint16_t)VALUE);

#define miniflow_push_be8_(MF, OFS, VALUE)                     \
    miniflow_push_uint8_(MF, OFS, (OVS_FORCE uint8_t)VALUE);

#define miniflow_set_maps(MF, OFS, N_WORDS)                     \
{                                                               \
    size_t ofs = (OFS);                                         \
    size_t n_words = (N_WORDS);                                 \
                                                                \
    MINIFLOW_ASSERT(n_words && MF.data + n_words <= MF.end);    \
    ASSERT_FLOWMAP_NOT_SET(&MF.map, ofs);                       \
    flowmap_set(&MF.map, ofs, n_words);                         \
}

/* Data at 'valuep' may be unaligned. */
#define miniflow_push_words_(MF, OFS, VALUEP, N_WORDS)          \
{                                                               \
    MINIFLOW_ASSERT((OFS) % 8 == 0);                            \
    miniflow_set_maps(MF, (OFS) / 8, (N_WORDS));                \
    memcpy(MF.data, (VALUEP), (N_WORDS) * sizeof *MF.data);     \
    MF.data += (N_WORDS);                                       \
}

/* Push 32-bit words padded to 64-bits. */
#define miniflow_push_words_32_(MF, OFS, VALUEP, N_WORDS)               \
{                                                                       \
    miniflow_set_maps(MF, (OFS) / 8, DIV_ROUND_UP(N_WORDS, 2));         \
    memcpy(MF.data, (VALUEP), (N_WORDS) * sizeof(uint32_t));            \
    MF.data += DIV_ROUND_UP(N_WORDS, 2);                                \
    if ((N_WORDS) & 1) {                                                \
        *((uint32_t *)MF.data - 1) = 0;                                 \
    }                                                                   \
}

/* Data at 'valuep' may be unaligned. */
/* MACs start 64-aligned, and must be followed by other data or padding. */
#define miniflow_push_macs_(MF, OFS, VALUEP)                    \
{                                                               \
    miniflow_set_maps(MF, (OFS) / 8, 2);                        \
    memcpy(MF.data, (VALUEP), 2 * ETH_ADDR_LEN);                \
    MF.data += 1;                   /* First word only. */      \
}

#define miniflow_push_uint32(MF, FIELD, VALUE)                      \
    miniflow_push_uint32_(MF, offsetof(struct flow, FIELD), VALUE)

#define miniflow_push_be32(MF, FIELD, VALUE)                        \
    miniflow_push_be32_(MF, offsetof(struct flow, FIELD), VALUE)

#define miniflow_push_uint16(MF, FIELD, VALUE)                      \
    miniflow_push_uint16_(MF, offsetof(struct flow, FIELD), VALUE)

#define miniflow_push_be16(MF, FIELD, VALUE)                        \
    miniflow_push_be16_(MF, offsetof(struct flow, FIELD), VALUE)

#define miniflow_push_uint8(MF, FIELD, VALUE)                      \
    miniflow_push_uint8_(MF, offsetof(struct flow, FIELD), VALUE)

#define miniflow_pad_to_64(MF, FIELD)                       \
    miniflow_pad_to_64_(MF, OFFSETOFEND(struct flow, FIELD))

#define miniflow_pad_from_64(MF, FIELD)                       \
    miniflow_pad_from_64_(MF, offsetof(struct flow, FIELD))

#define miniflow_push_words(MF, FIELD, VALUEP, N_WORDS)                 \
    miniflow_push_words_(MF, offsetof(struct flow, FIELD), VALUEP, N_WORDS)

#define miniflow_push_words_32(MF, FIELD, VALUEP, N_WORDS)              \
    miniflow_push_words_32_(MF, offsetof(struct flow, FIELD), VALUEP, N_WORDS)

#define miniflow_push_macs(MF, FIELD, VALUEP)                       \
    miniflow_push_macs_(MF, offsetof(struct flow, FIELD), VALUEP)

/* Return the pointer to the miniflow data when called BEFORE the corresponding
 * push. */
#define miniflow_pointer(MF, FIELD)                                     \
    (void *)((uint8_t *)MF.data + ((offsetof(struct flow, FIELD)) % 8))


# mpls
static inline int
parse_mpls(const void **datap, size_t *sizep)
{
    const struct mpls_hdr *mh;
    int count = 0;

    while ((mh = data_try_pull(datap, sizep, sizeof *mh))) {
        count++;
        if (mh->mpls_lse.lo & htons(1 << MPLS_BOS_SHIFT)) {
            break;
        }
    }
    return MIN(count, FLOW_MAX_MPLS_LABELS);
}

# vlan
/* passed vlan_hdrs arg must be at least size FLOW_MAX_VLAN_HEADERS. */
static inline ALWAYS_INLINE size_t
parse_vlan(const void **datap, size_t *sizep, union flow_vlan_hdr *vlan_hdrs)
{
    const ovs_be16 *eth_type;

    data_pull(datap, sizep, ETH_ADDR_LEN * 2);

    eth_type = *datap;

    size_t n;
    for (n = 0; eth_type_vlan(*eth_type) && n < flow_vlan_limit; n++) {
        if (OVS_UNLIKELY(*sizep < sizeof(ovs_be32) + sizeof(ovs_be16))) {
            break;
        }

        memset(vlan_hdrs + n, 0, sizeof(union flow_vlan_hdr));
        const ovs_16aligned_be32 *qp = data_pull(datap, sizep, sizeof *qp);
        vlan_hdrs[n].qtag = get_16aligned_be32(qp);
        vlan_hdrs[n].tci |= htons(VLAN_CFI);
        eth_type = *datap;
    }
    return n;
}

# ethertype
static inline ALWAYS_INLINE ovs_be16
parse_ethertype(const void **datap, size_t *sizep)
{
    const struct llc_snap_header *llc;
    ovs_be16 proto;

    proto = *(ovs_be16 *) data_pull(datap, sizep, sizeof proto);
    if (OVS_LIKELY(ntohs(proto) >= ETH_TYPE_MIN)) {
        return proto;
    }

    if (OVS_UNLIKELY(*sizep < sizeof *llc)) {
        return htons(FLOW_DL_TYPE_NONE);
    }

    llc = *datap;
    if (OVS_UNLIKELY(llc->llc.llc_dsap != LLC_DSAP_SNAP
                     || llc->llc.llc_ssap != LLC_SSAP_SNAP
                     || llc->llc.llc_cntl != LLC_CNTL_SNAP
                     || memcmp(llc->snap.snap_org, SNAP_ORG_ETHERNET,
                               sizeof llc->snap.snap_org))) {
        return htons(FLOW_DL_TYPE_NONE);
    }

    data_pull(datap, sizep, sizeof *llc);

    if (OVS_LIKELY(ntohs(llc->snap.snap_type) >= ETH_TYPE_MIN)) {
        return llc->snap.snap_type;
    }

    return htons(FLOW_DL_TYPE_NONE);
}

/* Returns 'true' if the packet is an ND packet. In that case the '*nd_target'
 * and 'arp_buf[]' are filled in.  If the packet is not an ND packet, 'false'
 * is returned and no values are filled in on '*nd_target' or 'arp_buf[]'. */
# icmpv6
static inline bool
parse_icmpv6(const void **datap, size_t *sizep,
             const struct icmp6_data_header *icmp6,
             ovs_be32 *rso_flags, const struct in6_addr **nd_target,
             struct eth_addr arp_buf[2], uint8_t *opt_type)
{
    if (icmp6->icmp6_base.icmp6_code != 0 ||
        (icmp6->icmp6_base.icmp6_type != ND_NEIGHBOR_SOLICIT &&
         icmp6->icmp6_base.icmp6_type != ND_NEIGHBOR_ADVERT)) {
        return false;
    }

    arp_buf[0] = eth_addr_zero;
    arp_buf[1] = eth_addr_zero;
    *opt_type = 0;

    *rso_flags = get_16aligned_be32(icmp6->icmp6_data.be32);

    *nd_target = data_try_pull(datap, sizep, sizeof **nd_target);
    if (OVS_UNLIKELY(!*nd_target)) {
        return true;
    }

    while (*sizep >= 8) {
        /* The minimum size of an option is 8 bytes, which also is
         * the size of Ethernet link-layer options. */
        const struct ovs_nd_lla_opt *lla_opt = *datap;
        int opt_len = lla_opt->len * ND_LLA_OPT_LEN;

        if (!opt_len || opt_len > *sizep) {
            return true;
        }

        /* Store the link layer address if the appropriate option is
         * provided.  It is considered an error if the same link
         * layer option is specified twice. */
        if (lla_opt->type == ND_OPT_SOURCE_LINKADDR && opt_len == 8) {
            if (OVS_LIKELY(eth_addr_is_zero(arp_buf[0]))) {
                arp_buf[0] = lla_opt->mac;
                /* We use only first option type present in ND packet. */
                if (*opt_type == 0) {
                    *opt_type = lla_opt->type;
                }
            } else {
                goto invalid;
            }
        } else if (lla_opt->type == ND_OPT_TARGET_LINKADDR && opt_len == 8) {
            if (OVS_LIKELY(eth_addr_is_zero(arp_buf[1]))) {
                arp_buf[1] = lla_opt->mac;
                /* We use only first option type present in ND packet. */
                if (*opt_type == 0) {
                    *opt_type = lla_opt->type;
                }
            } else {
                goto invalid;
            }
        }

        if (OVS_UNLIKELY(!data_try_pull(datap, sizep, opt_len))) {
            return true;
        }
    }
    return true;

invalid:
    *nd_target = NULL;
    arp_buf[0] = eth_addr_zero;
    arp_buf[1] = eth_addr_zero;
    return true;
}

# ipv6
static inline bool
parse_ipv6_ext_hdrs__(const void **datap, size_t *sizep, uint8_t *nw_proto,
                      uint8_t *nw_frag,
                      const struct ovs_16aligned_ip6_frag **frag_hdr)
{
    *frag_hdr = NULL;
    while (1) {
        if (OVS_LIKELY((*nw_proto != IPPROTO_HOPOPTS)
                       && (*nw_proto != IPPROTO_ROUTING)
                       && (*nw_proto != IPPROTO_DSTOPTS)
                       && (*nw_proto != IPPROTO_AH)
                       && (*nw_proto != IPPROTO_FRAGMENT))) {
            /* It's either a terminal header (e.g., TCP, UDP) or one we
             * don't understand.  In either case, we're done with the
             * packet, so use it to fill in 'nw_proto'. */
            return true;
        }

        /* We only verify that at least 8 bytes of the next header are
         * available, but many of these headers are longer.  Ensure that
         * accesses within the extension header are within those first 8
         * bytes. All extension headers are required to be at least 8
         * bytes. */
        if (OVS_UNLIKELY(*sizep < 8)) {
            return false;
        }

        if ((*nw_proto == IPPROTO_HOPOPTS)
            || (*nw_proto == IPPROTO_ROUTING)
            || (*nw_proto == IPPROTO_DSTOPTS)) {
            /* These headers, while different, have the fields we care
             * about in the same location and with the same
             * interpretation. */
            const struct ip6_ext *ext_hdr = *datap;
            *nw_proto = ext_hdr->ip6e_nxt;
            if (OVS_UNLIKELY(!data_try_pull(datap, sizep,
                                            (ext_hdr->ip6e_len + 1) * 8))) {
                return false;
            }
        } else if (*nw_proto == IPPROTO_AH) {
            /* A standard AH definition isn't available, but the fields
             * we care about are in the same location as the generic
             * option header--only the header length is calculated
             * differently. */
            const struct ip6_ext *ext_hdr = *datap;
            *nw_proto = ext_hdr->ip6e_nxt;
            if (OVS_UNLIKELY(!data_try_pull(datap, sizep,
                                            (ext_hdr->ip6e_len + 2) * 4))) {
                return false;
            }
        } else if (*nw_proto == IPPROTO_FRAGMENT) {
            *frag_hdr = *datap;

            *nw_proto = (*frag_hdr)->ip6f_nxt;
            if (!data_try_pull(datap, sizep, sizeof **frag_hdr)) {
                return false;
            }

            /* We only process the first fragment. */
            if ((*frag_hdr)->ip6f_offlg != htons(0)) {
                *nw_frag = FLOW_NW_FRAG_ANY;
                if (((*frag_hdr)->ip6f_offlg & IP6F_OFF_MASK) != htons(0)) {
                    *nw_frag |= FLOW_NW_FRAG_LATER;
                    *nw_proto = IPPROTO_FRAGMENT;
                    return true;
                }
            }
        }
    }
}

# ipv6
bool
parse_ipv6_ext_hdrs(const void **datap, size_t *sizep, uint8_t *nw_proto,
                    uint8_t *nw_frag,
                    const struct ovs_16aligned_ip6_frag **frag_hdr)
{
    return parse_ipv6_ext_hdrs__(datap, sizep, nw_proto, nw_frag,
                                 frag_hdr);
}

# nsh(default)
bool
parse_nsh(const void **datap, size_t *sizep, struct ovs_key_nsh *key)
{
    const struct nsh_hdr *nsh = (const struct nsh_hdr *) *datap;
    uint8_t version, length, flags, ttl;

    /* Check if it is long enough for NSH header, doesn't support
     * MD type 2 yet
     */
    if (OVS_UNLIKELY(*sizep < NSH_BASE_HDR_LEN)) {
        return false;
    }

    version = nsh_get_ver(nsh);
    flags = nsh_get_flags(nsh);
    length = nsh_hdr_len(nsh);
    ttl = nsh_get_ttl(nsh);

    if (OVS_UNLIKELY(length > *sizep || version != 0)) {
        return false;
    }

    key->flags = flags;
    key->ttl = ttl;
    key->mdtype = nsh->md_type;
    key->np = nsh->next_proto;
    key->path_hdr = nsh_get_path_hdr(nsh);

    switch (key->mdtype) {
        case NSH_M_TYPE1:
            if (length != NSH_M_TYPE1_LEN) {
                return false;
            }
            for (size_t i = 0; i < 4; i++) {
                key->context[i] = get_16aligned_be32(&nsh->md1.context[i]);
            }
            break;
        case NSH_M_TYPE2:
            /* Don't support MD type 2 metedata parsing yet */
            if (length < NSH_BASE_HDR_LEN) {
                return false;
            }

            memset(key->context, 0, sizeof(key->context));
            break;
        default:
            /* We don't parse other context headers yet. */
            memset(key->context, 0, sizeof(key->context));
            break;
    }

    data_pull(datap, sizep, length);

    return true;
}

/* This does the same thing as miniflow_extract() with a full-size 'flow' as
 * the destination. */
void
flow_extract(struct dp_packet *packet, struct flow *flow)
{
    struct {
        struct miniflow mf;
        uint64_t buf[FLOW_U64S];
    } m;

    COVERAGE_INC(flow_extract);

    miniflow_extract(packet, &m.mf);
    miniflow_expand(&m.mf, flow);
}

# ipv4
static inline bool
ipv4_sanity_check(const struct ip_header *nh, size_t size,
                  int *ip_lenp, uint16_t *tot_lenp)
{
    int ip_len;
    uint16_t tot_len;

    if (OVS_UNLIKELY(size < IP_HEADER_LEN)) {
        COVERAGE_INC(miniflow_extract_ipv4_pkt_too_short);
        return false;
    }
    ip_len = IP_IHL(nh->ip_ihl_ver) * 4;

    if (OVS_UNLIKELY(ip_len < IP_HEADER_LEN || size < ip_len)) {
        COVERAGE_INC(miniflow_extract_ipv4_pkt_len_error);
        return false;
    }

    tot_len = ntohs(nh->ip_tot_len);
    if (OVS_UNLIKELY(tot_len > size || ip_len > tot_len ||
                size - tot_len > UINT16_MAX)) {
        COVERAGE_INC(miniflow_extract_ipv4_pkt_len_error);
        return false;
    }

    *ip_lenp = ip_len;
    *tot_lenp = tot_len;

    return true;
}

# ipv4
static inline uint8_t
ipv4_get_nw_frag(const struct ip_header *nh)
{
    uint8_t nw_frag = 0;

    if (OVS_UNLIKELY(IP_IS_FRAGMENT(nh->ip_frag_off))) {
        nw_frag = FLOW_NW_FRAG_ANY;
        if (nh->ip_frag_off & htons(IP_FRAG_OFF_MASK)) {
            nw_frag |= FLOW_NW_FRAG_LATER;
        }
    }

    return nw_frag;
}

# ipv6
static inline bool
ipv6_sanity_check(const struct ovs_16aligned_ip6_hdr *nh, size_t size)
{
    uint16_t plen;

    if (OVS_UNLIKELY(size < sizeof *nh)) {
        COVERAGE_INC(miniflow_extract_ipv6_pkt_too_short);
        return false;
    }

    plen = ntohs(nh->ip6_plen);
    if (OVS_UNLIKELY(plen + IPV6_HEADER_LEN > size)) {
        COVERAGE_INC(miniflow_extract_ipv6_pkt_len_error);
        return false;
    }

    if (OVS_UNLIKELY(size - (plen + IPV6_HEADER_LEN) > UINT16_MAX)) {
        COVERAGE_INC(miniflow_extract_ipv6_pkt_len_error);
        return false;
    }

    return true;
}

# ipv4
static void
dump_invalid_packet(struct dp_packet *packet, const char *reason)
{
    static struct vlog_rate_limit rl = VLOG_RATE_LIMIT_INIT(1, 5);
    struct ds ds = DS_EMPTY_INITIALIZER;
    size_t size;

    if (VLOG_DROP_DBG(&rl)) {
        return;
    }
    size = dp_packet_size(packet);
    ds_put_hex_dump(&ds, dp_packet_data(packet), size, 0, false);
    VLOG_DBG("invalid packet for %s: port %"PRIu32", size %"PRIuSIZE"\n%s",
             reason, packet->md.in_port.odp_port, size, ds_cstr(&ds));
    ds_destroy(&ds);
}